# 顔年齢推定プロジェクト：関数・処理・技術メモ完全一覧

このプロジェクトにおける各スクリプトの役割と、コード内の重要な関数、および実装上の注意点を網羅的にまとめました。

---

## 1. データセットの準備と整形 (`dataset.py`)
データの不均衡を是正し、PyTorchで扱える形に変換する最重要フェーズです。

| 項目 (関数・クラス) | 引数・属性 | 説明と「開発者のメモ」 |
| :--- | :--- | :--- |
| `load_dataset` | `DATASET_NAME` | Hugging Faceからデータをロード。戻り値は辞書型の `DatasetDict`。 |
| `pd.DataFrame` | `dataset['train']` | 統計処理やサンプリングをしやすくするため、一度Pandasの表形式に変換。 |
| `np.array(img)` | `lambda` 内で使用 | **【重要】** PIL Imageのままだと `shape` が持てないため、計算用にNumPy配列化。 |
| `groupby().sample()` | `n=min_count` | **【解決策】** 最小クラス（344枚）に合わせて他を削る「アンダーサンプリング」を実行。バイアスを防ぐ。 |
| `train_test_split` | `stratify=df['label']` | **【重要】** 分割後もラベルの比率（0〜7）が崩れないように均等に分ける設定。 |
| `MyDataset(Dataset)` | `(self, df, transform)` | `torch.utils.data.Dataset` を継承。独自のデータ読み出しルールを定義。 |
| `Image.fromarray()` | `image` | NumPy配列を再度PILに戻す。`torchvision.transforms` を適用するために必須。 |
| `transforms.Normalize` | `mean/std=[0.5]*3` | **【鏡合わせの原則】** データを [-1, 1] に正規化。推論時と絶対一致させること。 |
| `DataLoader` | `shuffle=True/False` | バッチサイズ(32)ごとにデータを供給。学習用はエポックごとに順序をシャッフル。 |
| `if __name__ == "__main__":` | - | **【副作用対策】** 他のファイルから `import` された時に、データ準備処理が誤作動するのを防ぐガード。 |

---

## 2. ネットワーク構築と学習ループ (`pytorchCNNnew.py`)
モデルの背骨（アーキテクチャ）と、重みを更新するロジックです。

| 項目 (関数・クラス) | 引数・属性 | 説明と「開発者のメモ」 |
| :--- | :--- | :--- |
| `nn.Conv2d` | `(in, out, kernel, pad)` | 畳み込み層。32→64→128→256と段階的に特徴量を増やし、情報の解像度を高める。 |
| `nn.Dropout(0.5)` | `p=0.5` | **【過学習抑制】** 50%のノードをランダムに休ませ、特定のパターンへの固執を防ぐ。 |
| `nn.AdaptiveAvgPool2d` | `(1, 1)` | **【GAP】** どんなサイズの画像が入ってきても最終的に 1x1 に圧縮。全結合層への橋渡し。 |
| `torch.flatten` | `(x, 1)` | GAP後の (Batch, 256, 1, 1) を (Batch, 256) に平坦化し、線形層へ入力可能にする。 |
| `nn.CrossEntropyLoss` | - | 分類問題の定番。予測と正解の「ズレ」を計算。内部で Softmax を含む。 |
| `optim.Adam` | `lr=0.001` | 最適化アルゴリズム。学習率(lr)は、データ削減後は低め(0.001)に設定して丁寧に更新。 |
| `optimizer.zero_grad()` | - | **【必須メモ】** 各バッチの最初で勾配をゼロにリセット。これを忘れると過去の勾配が累積して壊れる。 |
| `loss.backward()` | - | 誤差逆伝播。損失を元に、どの重みをどう変えるべきか（勾配）を計算。 |
| `optimizer.step()` | - | 計算された勾配を使い、実際にモデルの重み（パラメータ）を更新。 |
| `Counter()` | `labels.tolist()` | 学習中の各エポックで、実際にどのラベルが何枚処理されたかを確認するデバッグ用。 |
| `torch.save()` | `state_dict()` | 学習完了後、モデルの「重み」だけを `.pth` ファイルとして保存。 |

---

## 3. 推論（外部画像テスト） (`load.py`)
完成したモデルを使い、未知の画像（URL）に対して予測を行うフェーズです。

| 項目 (関数・クラス) | 引数・属性 | 説明と「開発者のメモ」 |
| :--- | :--- | :--- |
| `model.load_state_dict` | `torch.load(path)` | 保存した `.pth` を読み込む。**学習時と全く同じ `MyCNN` クラス定義が必要。** |
| `model.eval()` | - | **【推論モード】** Dropoutなどの「学習時専用機能」をオフにする。 |
| `torch.no_grad()` | (context manager) | **【メモリ節約】** 勾配計算を停止。推論を高速化し、VRAM消費を抑える。 |
| `requests.get()` | `url` | ネット上の画像をバイナリとして取得。 |
| `BytesIO(content)` | `response.content` | 取得したバイナリデータを、Pythonがファイルとして扱えるメモリ上のストリームに変換。 |
| `unsqueeze(0)` | `dim=0` | 画像(3, 200, 200)にバッチ次元を追加し、(1, 3, 200, 200)にする。 |
| `outputs.argmax(1)` | `dim=1` | 8クラスのスコアのうち、最も数値が高い「クラス番号（年齢層）」を取得。 |

---

## 💡 プロジェクト全体の技術的ポイント
* **データ不均衡対策:** `sample(n=min_count)` によるアンダーサンプリング。
* **型の変遷:** `HuggingFace Dataset` → `Pandas` → `NumPy` → `PIL` → `Tensor` という流れを制御。
* **正規化の統一:** `mean=0.5, std=0.5` を学習・推論の両方で徹底。
* **例外処理:** `try-except` や `response.status_code` による、不安定な外部URL取得への対策。